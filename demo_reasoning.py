import cv2
import numpy as np
from PIL import Image
import os
import sys
import torch
import json
from AECIF_Net import HRnet_Segmentation
from openai import OpenAI

# ==========================================
# 1. é…ç½®åŒºåŸŸ (Groq å…è´¹æ–¹æ¡ˆ)
# ==========================================
# ğŸ”‘ è¯·åœ¨è¿™é‡Œå¡«å…¥ä½ çš„ Groq Key (ä»¥ gsk_ å¼€å¤´)
API_KEY = "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"

# Groq çš„é…ç½® (ä¸è¦æ”¹)
BASE_URL = "https://api.groq.com/openai/v1"
# MODEL_NAME = "llama3-8b-8192"  # é€Ÿåº¦æå¿«çš„ Llama 3 æ¨¡å‹
MODEL_NAME = "llama-3.3-70b-versatile"

# æ–‡ä»¶è·¯å¾„
WEIGHT_FILE = 'model_data/best_epoch_weights.pth'
TEST_IMAGE = 'img/1.jpg'


# ==========================================
# 2. è¿™é‡Œçš„ Prompt æ˜¯æ ¸å¿ƒï¼šå®šä¹‰äº† LLM çš„ä¸–ç•Œè§‚
# ==========================================
def ask_ai_universal(user_query):
    print(f"\n[AI Brain] åˆ†æç”¨æˆ·æ„å›¾: '{user_query}' ...")

    if "gsk_" not in API_KEY and "sk-" not in API_KEY:
        print("âŒ é”™è¯¯: è¯·å¡«å…¥ API Key")
        return None

    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

    # ğŸŒŸ æ ¸å¿ƒå‡çº§ï¼šè®© LLM æˆä¸ºé€»è¾‘åˆ†æå¸ˆ
    system_prompt = """
    You are an intelligent Bridge Inspection Agent. 
    You have access to a segmented image with the following available data layers (Masks):

    ã€Data Layersã€‘
    - ELEMENTS: Bearing(1), Bracing(2), Deck(3), Floor Beam(4), Girder(5), Pier(6)
    - DEFECTS: Rust(1)

    ã€Your Jobã€‘
    Translate the user's natural language query into a strict JSON execution plan.
    You must decide logically how to combine these layers to answer the user.

    ã€Logic Typesã€‘
    1. "Show me X": Visualize specific targets.
    2. "Show X on Y" (Intersection): You want to see defects (X) ONLY within the area of an element (Y).
    3. "How much X?" / "Is it serious?": Calculate the area percentage.
    4. "Is there any X?": Check if the mask area > 0.

    ã€Output JSON Schemaã€‘
    {
        "intent": "visualize" | "analyze", 
        "target_layers": [{"type": "elements"|"defects", "id": int, "name": str}, ...],
        "constraint_layer": {"type": "elements", "id": int, "name": str} | null,
        "description": "Short explanation of the logic (e.g., 'Calculating rust coverage on the girder')"
    }

    ã€Examplesã€‘
    - User: "Where is the girder?" 
      -> {"intent": "visualize", "target_layers": [{"type": "elements", "id": 5, "name": "Girder"}], "constraint_layer": null, "description": "Locating girder"}

    - User: "Show me the rust on the floor beam" 
      -> {"intent": "visualize", "target_layers": [{"type": "defects", "id": 1, "name": "Rust"}], "constraint_layer": {"type": "elements", "id": 4, "name": "Floor Beam"}, "description": "Filtering rust on floor beam"}

    - User: "How bad is the corrosion on the pier?" 
      -> {"intent": "analyze", "target_layers": [{"type": "defects", "id": 1, "name": "Rust"}], "constraint_layer": {"type": "elements", "id": 6, "name": "Pier"}, "description": "Calculating rust percentage on pier"}

    - User: "Is the bridge safe?" (Implies checking for defects)
      -> {"intent": "analyze", "target_layers": [{"type": "defects", "id": 1, "name": "Rust"}], "constraint_layer": null, "description": "Checking total corrosion amount"}
    """

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query},
            ],
            temperature=0.1,
        )
        content = response.choices[0].message.content
        content = content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)

    except Exception as e:
        print(f"âŒ AI è§£æå¤±è´¥: {e}")
        return None


# ==========================================
# 3. æ™ºèƒ½åŠ è½½å™¨
# ==========================================
def load_model_smartly():
    print(f"ğŸš€ åˆå§‹åŒ– AECIF-Net...")
    try:
        if torch.cuda.is_available():
            dummy = torch.tensor([1.0]).cuda()
            res = dummy + 1.0
            print("âœ… GPU æ¨¡å¼å¯åŠ¨ï¼")
            return HRnet_Segmentation(model_path=WEIGHT_FILE, cuda=True)
    except RuntimeError:
        pass
    print("ğŸ”„ ä½¿ç”¨ CPU æ¨¡å¼...")
    return HRnet_Segmentation(model_path=WEIGHT_FILE, cuda=False)


# ==========================================
# 4. æ‰§è¡Œå¼•æ“ (Python Logic)
# ==========================================
def execute_plan(hrnet, image, plan):
    img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    h, w = img_cv.shape[:2]

    print(f"âš™ï¸ [Executor] æ‰§è¡Œé€»è¾‘: {plan['description']}")

    # 1. è·å–æ‰€æœ‰åŸå§‹ Mask
    mask_e, mask_d = hrnet.get_raw_masks(image)

    # 2. æ„å»ºã€ç›®æ ‡é›†åˆã€‘ (Target Mask)
    # é€»è¾‘ï¼šå¤šä¸ªç›®æ ‡ä¹‹é—´å–å¹¶é›† (Union)
    target_mask = np.zeros((h, w), dtype=np.uint8)
    target_names = []

    for item in plan['target_layers']:
        target_names.append(item['name'])
        if item['type'] == 'elements':
            target_mask = cv2.bitwise_or(target_mask, (mask_e == item['id']).astype(np.uint8))
        elif item['type'] == 'defects':
            target_mask = cv2.bitwise_or(target_mask, (mask_d == item['id']).astype(np.uint8))

    # 3. æ„å»ºã€çº¦æŸé›†åˆã€‘ (Constraint Mask)
    # é€»è¾‘ï¼šå¦‚æœæœ‰çº¦æŸï¼Œå–äº¤é›† (Intersection)
    roi_mask = None
    if plan['constraint_layer']:
        c_item = plan['constraint_layer']
        print(f"   -> æ–½åŠ ç©ºé—´çº¦æŸ: ä»…é™ {c_item['name']} åŒºåŸŸ")
        if c_item['type'] == 'elements':
            roi_mask = (mask_e == c_item['id']).astype(np.uint8)
        else:
            roi_mask = (mask_d == c_item['id']).astype(np.uint8)

        # æ ¸å¿ƒï¼šç›®æ ‡ AND çº¦æŸ
        target_mask = cv2.bitwise_and(target_mask, roi_mask)

    # 4. åˆ†æä¸è®¡ç®— (Analysis)
    pixel_count = np.sum(target_mask > 0)
    report_text = ""

    if plan['intent'] == 'analyze':
        if pixel_count == 0:
            report_text = "Analysis Result: None detected."
        else:
            # å¦‚æœæœ‰çº¦æŸåŒºåŸŸï¼Œè®¡ç®—ç›¸å¯¹æ¯”ä¾‹
            if roi_mask is not None:
                roi_pixels = np.sum(roi_mask > 0)
                if roi_pixels > 0:
                    ratio = (pixel_count / roi_pixels) * 100
                    report_text = f"Severity: {ratio:.2f}% of {plan['constraint_layer']['name']} is affected."
                else:
                    report_text = "Constraint area not found."
            else:
                # å¦åˆ™è®¡ç®—å…¨å›¾æ¯”ä¾‹
                ratio = (pixel_count / (h * w)) * 100
                report_text = f"Coverage: {ratio:.2f}% of total image."

        print(f"ğŸ“Š [Report] {report_text}")

    elif plan['intent'] == 'visualize':
        if pixel_count > 0:
            report_text = f"Visualizing: {', '.join(target_names)}"
        else:
            report_text = f"Not Found: {', '.join(target_names)}"

    # 5. å¯è§†åŒ–æ¸²æŸ“
    if pixel_count > 0:
        overlay = img_cv.copy()

        # æ¸²æŸ“ç›®æ ‡ (çº¢è‰²é«˜äº®)
        overlay[target_mask > 0] = [0, 0, 255]

        # å¦‚æœæœ‰çº¦æŸåŒºåŸŸï¼ŒæŠŠçº¦æŸåŒºåŸŸä¹Ÿç”»ä¸ªæ·¡æ·¡çš„è½®å»“ï¼ˆæ¯”å¦‚è“è‰²ï¼‰ï¼Œæ–¹ä¾¿å¯¹æ¯”
        if roi_mask is not None:
            contours_roi, _ = cv2.findContours(roi_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            cv2.drawContours(img_cv, contours_roi, -1, (255, 0, 0), 1)  # è“è‰²ç»†çº¿è¡¨ç¤ºçº¦æŸèŒƒå›´

        # æ··åˆ
        res_img = cv2.addWeighted(img_cv, 0.7, overlay, 0.3, 0)

        # ç”»ç›®æ ‡è½®å»“ (é»„è‰²)
        contours, _ = cv2.findContours(target_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(res_img, contours, -1, (0, 255, 255), 2)

        # åœ¨å›¾ä¸Šå†™æŠ¥å‘Š
        cv2.rectangle(res_img, (0, 0), (w, 50), (0, 0, 0), -1)
        cv2.putText(res_img, report_text, (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        cv2.imshow("Bridge Analysis Agent", res_img)
        print("âœ… ç»“æœå±•ç¤ºä¸­ï¼ŒæŒ‰ä»»æ„é”®ç»§ç»­...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    else:
        print(f"âš ï¸ åˆ†æç»“æœ: æœªåœ¨æŒ‡å®šåŒºåŸŸæ£€æµ‹åˆ°ç›¸å…³ç›®æ ‡ã€‚")


# ==========================================
# 5. ä¸»å…¥å£
# ==========================================
if __name__ == "__main__":
    if not os.path.exists(WEIGHT_FILE):
        sys.exit("âŒ æƒé‡æ–‡ä»¶ä¸¢å¤±")
    if not os.path.exists(TEST_IMAGE):
        sys.exit("âŒ å›¾ç‰‡ä¸¢å¤±")

    hrnet = load_model_smartly()
    image = Image.open(TEST_IMAGE)

    print("\nğŸ’¡ å°è¯•é—®æˆ‘å„ç§é—®é¢˜:")
    print(" - 'Is the pier rusted?' (åˆ¤æ–­)")
    print(" - 'How bad is the corrosion on the girder?' (å®šé‡åˆ†æ)")
    print(" - 'Where are the bearings?' (å®šä½)")
    print(" - 'Show me rust and cracks' (LLMä¼šçŸ¥é“crackä¸åœ¨æ•°æ®åº“é‡Œ)")

    while True:
        query = input("\nğŸ’¬ Bridge Agent (You): ")
        if query.lower() in ['q', 'quit']: break

        plan = ask_ai_universal(query)
        if plan:
            execute_plan(hrnet, image, plan)